{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# http://bit.ly/wsd-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша первая задача - научиться делать Word Sense Disambiguation (WSD) при помощи семантических векторов.\n",
    "Все необходимые библиотеки можно поставить при помощи команды\n",
    "\n",
    "    pip install -U numpy scipy scikit-learn gensim rl_wsd_labeled\n",
    "    \n",
    "Скачайте word2vec модель по ссылке https://s3-us-west-2.amazonaws.com/models-tmp/sg_all_d256_m100.kv.zip и распакуйте архив.\n",
    "\n",
    "Загрузим word2vec модель при помощи библиотеки [gensim](https://radimrehurek.com/gensim/models/word2vec.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v_model = KeyedVectors.load('sg_all_d256_m100.kv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта модель возвращает вектор по слову:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.92402732e-02,  -2.33064741e-01,   2.67826408e-01,\n",
       "         2.18009073e-02,   1.52654126e-01,   6.13806583e-02,\n",
       "         6.64153993e-02,   1.67186111e-01,   3.27731252e-01,\n",
       "         1.79390356e-01,  -3.11140954e-01,   8.65942463e-02,\n",
       "        -1.43792189e-03,   7.60920644e-02,  -2.56183594e-01,\n",
       "         6.73418567e-02,   1.23391822e-02,  -2.60421127e-01,\n",
       "        -6.60199463e-01,   7.46247619e-02,   5.24061732e-02,\n",
       "         1.64030977e-02,   2.95160413e-01,  -3.17132776e-03,\n",
       "         6.80546910e-02,  -5.99196404e-02,   1.16859920e-01,\n",
       "         4.61518653e-02,   9.31969285e-02,   2.19365045e-01,\n",
       "         2.76627213e-01,  -4.56820391e-02,  -2.70343926e-02,\n",
       "        -1.62638649e-02,   4.17803228e-02,   8.82430002e-02,\n",
       "         1.68497086e-01,   1.37637436e-01,   1.47348672e-01,\n",
       "         3.52509655e-02,  -1.44522265e-01,   9.19886008e-02,\n",
       "         1.16782561e-01,  -5.47234975e-02,   1.24640822e-01,\n",
       "        -3.25096361e-02,  -4.08213139e-02,   2.04653814e-02,\n",
       "        -2.44065523e-01,   1.24497011e-01,  -2.07736325e-02,\n",
       "         1.09991066e-01,  -1.49910703e-01,   2.94663876e-01,\n",
       "        -1.49659172e-01,  -3.47722769e-02,  -3.08758374e-02,\n",
       "        -1.99638546e-01,  -1.16502225e-01,  -6.19049408e-02,\n",
       "        -4.10370119e-02,  -3.14593390e-02,  -4.58040554e-03,\n",
       "        -1.31018490e-01,  -7.17378929e-02,  -2.51129130e-03,\n",
       "        -6.41953051e-02,  -1.71672441e-02,  -3.31785709e-01,\n",
       "        -3.44224662e-01,   2.72244394e-01,   1.16130218e-01,\n",
       "        -1.36881366e-01,   8.05212408e-02,   1.28675252e-01,\n",
       "        -3.13640803e-01,   1.58607289e-01,  -9.50028151e-02,\n",
       "        -2.62288332e-01,   1.05343528e-01,   2.30518326e-01,\n",
       "        -8.37909728e-02,  -1.18953548e-01,  -3.27648036e-02,\n",
       "        -1.53126985e-01,  -1.79714113e-01,   4.74427938e-02,\n",
       "         1.89552009e-01,  -8.10040087e-02,  -6.74432740e-02,\n",
       "        -1.83197603e-01,   5.02181016e-02,  -1.14394449e-01,\n",
       "         2.32218802e-01,  -2.28117198e-01,  -2.99979970e-02,\n",
       "        -1.63062081e-01,   2.22683065e-02,  -1.36415854e-01,\n",
       "         7.86033347e-02,  -2.30432287e-01,  -6.22115040e-04,\n",
       "        -6.64364770e-02,  -1.78573858e-02,  -1.89102530e-01,\n",
       "         1.73717052e-01,  -3.93865332e-02,   3.11189287e-05,\n",
       "        -1.04582468e-02,   2.76410133e-01,  -1.34334788e-01,\n",
       "         3.95973306e-03,   3.34162228e-02,   2.40483843e-02,\n",
       "        -8.51788595e-02,   3.19692016e-01,  -3.60441595e-01,\n",
       "        -8.34022090e-02,   2.38843951e-02,  -6.90564588e-02,\n",
       "         3.57617348e-01,  -7.30574355e-02,   1.64313599e-01,\n",
       "        -2.88284630e-01,  -1.54946595e-01,  -1.00485347e-01,\n",
       "         2.02896550e-01,   4.90681492e-02,  -7.47562945e-02,\n",
       "        -1.31990582e-01,  -1.16044328e-01,  -8.81946310e-02,\n",
       "        -1.15650989e-01,   8.69556218e-02,   8.00992772e-02,\n",
       "         2.34886736e-01,   1.77007750e-01,  -2.35155180e-01,\n",
       "        -1.47294804e-01,   6.48861378e-02,  -8.21166709e-02,\n",
       "        -4.08611566e-01,   6.82371706e-02,  -3.35957408e-01,\n",
       "         5.59689663e-02,   7.04598054e-02,  -2.51560926e-01,\n",
       "         6.16257451e-02,   7.92297795e-02,  -2.32568920e-01,\n",
       "        -1.51056582e-02,  -9.19570997e-02,  -1.37118563e-01,\n",
       "        -8.51202905e-02,  -1.59737319e-02,   1.91246361e-01,\n",
       "        -1.10665657e-01,  -9.58445389e-03,  -2.97217846e-01,\n",
       "         1.83644518e-01,   2.13792205e-01,  -2.49041572e-01,\n",
       "         1.45759076e-01,  -1.17234074e-01,  -5.84646352e-02,\n",
       "         2.62589902e-01,  -3.60544503e-01,   1.80318952e-01,\n",
       "        -1.78380013e-01,   1.69887673e-02,   3.71530652e-02,\n",
       "         1.80802092e-01,  -7.41524771e-02,  -8.51842538e-02,\n",
       "        -1.89487159e-01,   3.46710160e-02,  -7.91066512e-02,\n",
       "        -6.94432259e-02,   1.25206694e-01,  -2.09649876e-02,\n",
       "         1.65284216e-01,  -1.49071693e-01,   3.12115639e-01,\n",
       "        -3.38269472e-02,  -2.28348970e-01,   1.42726198e-01,\n",
       "        -2.12094888e-01,  -2.51339406e-01,  -3.21937948e-01,\n",
       "         4.05432165e-01,  -2.93176562e-01,  -2.15583271e-03,\n",
       "        -3.48285176e-02,  -1.11141309e-01,  -3.14779401e-01,\n",
       "         1.98319316e-01,   1.50600374e-01,   6.02813773e-02,\n",
       "         2.28427187e-01,  -2.01348644e-02,  -4.08910075e-03,\n",
       "         1.30471690e-02,   5.86973205e-02,   3.03416014e-01,\n",
       "         2.98715740e-01,  -9.51301190e-04,  -1.37505413e-03,\n",
       "         1.28275678e-01,   2.52274662e-01,   5.50801605e-02,\n",
       "        -2.56904453e-01,  -2.35785782e-01,  -2.11771727e-02,\n",
       "         2.87148863e-01,  -1.89358637e-01,  -1.54187307e-02,\n",
       "         1.70599878e-01,   2.19861701e-01,  -1.13791637e-01,\n",
       "        -7.48357996e-02,  -8.19091033e-03,   1.06747121e-01,\n",
       "         4.72573377e-02,  -4.58296426e-02,  -1.56741947e-01,\n",
       "         1.94191560e-01,   2.79102415e-01,  -2.60988116e-01,\n",
       "        -1.02922142e-01,   1.41406670e-01,  -6.32571131e-02,\n",
       "         1.51290148e-01,  -4.06661071e-02,  -2.22536474e-01,\n",
       "         7.67446682e-02,   4.65120096e-03,  -4.51799333e-02,\n",
       "        -3.45152207e-02,  -8.78585353e-02,  -3.26090232e-02,\n",
       "         1.89857379e-01,   1.09932937e-01,  -2.15246063e-02,\n",
       "        -9.22686011e-02,  -2.34866627e-02,   3.10107619e-01,\n",
       "        -8.64191577e-02,   2.69079685e-01,   3.02633911e-01,\n",
       "         5.25650494e-02,   3.97759974e-02,   4.86199446e-02,\n",
       "        -8.53703097e-02,  -2.46181473e-01,   1.86476201e-01,\n",
       "        -1.00504585e-01], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model['горшок']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model['горшок'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Она построена по лемматизированному корпусу, так что слова \"горшка\" в ней нет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'горшка' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bfd77f94926f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'горшка'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kostia/programming/ling/sensefreq/venv/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kostia/programming/ling/sensefreq/venv/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'горшка' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "w2v_model['горшка']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим размеченные контексты для слова \"горшок\".\n",
    "\n",
    "Мы занимаемся WSD, это supervised задача, так что нам нужны размеченные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rl_wsd_labeled\n",
    "\n",
    "senses, contexts = rl_wsd_labeled.get_contexts(\n",
    "    rl_wsd_labeled.contexts_filename('nouns', 'RuTenTen', 'горшок'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Округлый глиняный сосуд для приготовления пищи (печной горшок)',\n",
       " '2': 'Расширяющийся кверху сосуд с отверстием в дне (цветочный горшок)',\n",
       " '3': 'Ночной горшок'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый контекст имеет левую часть, слово для которого мы разметили значение, и правую часть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(406,\n",
       " [(('телевизор, - ковер, , - музыкальный центр, - стол, - аквариум, - 3 шкафа, - цветы в',\n",
       "    ' горшках',\n",
       "    ', - мелкие аксессуары.'),\n",
       "   '2'),\n",
       "  (('перевалить в больший горшок, стараясь не повредить корни. Я выращиваю базилик в',\n",
       "    ' горшках',\n",
       "    ' объемом 0,7-1 литр. Этого ему вполне хватает. Можно брать горшки большего объема'),\n",
       "   '2'),\n",
       "  (('удобрениями. Весна это лучшее время для preszhdane горшечные растения в больший',\n",
       "    ' горшок',\n",
       "    ' со свежей почвой. Большинство из нас хорошо знают chitatelite эту практику, так'),\n",
       "   '2')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contexts), contexts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('перевалить в больший горшок, стараясь не повредить корни. Я выращиваю базилик в',\n",
       " ' объемом 0,7-1 литр. Этого ему вполне хватает. Можно брать горшки большего объема')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left, _, right = contexts[1][0]\n",
    "left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно что контексты не лемматизованы, но в нашей модели есть только лемматизованые слова. Исправим это - загрузим mystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['перевалить',\n",
       " ' ',\n",
       " 'в',\n",
       " ' ',\n",
       " 'больший',\n",
       " ' ',\n",
       " 'горшок',\n",
       " ', ',\n",
       " 'стараться',\n",
       " ' ',\n",
       " 'не',\n",
       " ' ',\n",
       " 'повреждать',\n",
       " ' ',\n",
       " 'корень',\n",
       " '. ',\n",
       " 'я',\n",
       " ' ',\n",
       " 'выращивать',\n",
       " ' ',\n",
       " 'базилик',\n",
       " ' ',\n",
       " 'в',\n",
       " '\\n']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem.lemmatize(left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нас будут интересовать только слова, отбросим знаки препинания и разделители:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['перевалить',\n",
       " 'в',\n",
       " 'больший',\n",
       " 'горшок',\n",
       " 'стараться',\n",
       " 'не',\n",
       " 'повреждать',\n",
       " 'корень',\n",
       " 'я',\n",
       " 'выращивать',\n",
       " 'базилик',\n",
       " 'в']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(s):\n",
    "    return [t for t in mystem.lemmatize(s)\n",
    "            if re.match('\\w+$', t)]\n",
    "\n",
    "tokenize(left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь построим векторное представление контекста: возьмем среднее векторов всех слов контекста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00135083, -0.08833592,  0.02749542, -0.03430157,  0.04990597,\n",
       "       -0.00351785, -0.0377895 ,  0.04325328,  0.03681576,  0.00777959,\n",
       "       -0.09153348,  0.00741439, -0.00175712, -0.00361062, -0.06431929,\n",
       "        0.03168813, -0.03431803, -0.04016968, -0.12728518, -0.05535114,\n",
       "        0.05995908,  0.00678083,  0.01118196, -0.03073232,  0.00444479,\n",
       "       -0.10487767, -0.02356375, -0.00680911,  0.05342769,  0.03441216,\n",
       "        0.05997094, -0.0200747 ,  0.04236873, -0.03816266,  0.02926661,\n",
       "       -0.00959332,  0.03278689,  0.01879168,  0.07646055, -0.01720432,\n",
       "       -0.06004086, -0.02325079, -0.01187328,  0.04816246, -0.02895397,\n",
       "       -0.02052972, -0.0224539 ,  0.03614068, -0.01640125, -0.00932809,\n",
       "       -0.02643445,  0.10471622,  0.02175801,  0.10195923, -0.10238061,\n",
       "       -0.01712064,  0.00831175,  0.00393068,  0.00358072,  0.02274694,\n",
       "        0.0065462 , -0.05434006,  0.01133153, -0.03383037,  0.03999662,\n",
       "        0.06762768, -0.0840156 ,  0.00743738, -0.05133355,  0.01078196,\n",
       "        0.13165867,  0.13450198,  0.12699939,  0.0208452 , -0.04155504,\n",
       "        0.04956708,  0.01050893,  0.03478163, -0.04853095,  0.00692749,\n",
       "        0.05363579,  0.01288923,  0.05103609, -0.09243559,  0.00862609,\n",
       "       -0.03112323, -0.03754478, -0.02253093, -0.00841954, -0.03550788,\n",
       "        0.01611361, -0.03649331, -0.00928757,  0.18180434, -0.04027152,\n",
       "       -0.05845421, -0.03472285, -0.0384818 , -0.05542607, -0.00234002,\n",
       "       -0.05277481, -0.0404815 ,  0.01556445,  0.08024812, -0.09055059,\n",
       "       -0.12431511, -0.12073034, -0.07005809, -0.00945579,  0.00713193,\n",
       "       -0.10601895, -0.00325815,  0.06735002, -0.00876638,  0.00595756,\n",
       "        0.07913685, -0.11375415, -0.00966474,  0.0755265 ,  0.00800842,\n",
       "        0.06276844,  0.07633035,  0.07353847, -0.07400496, -0.00443737,\n",
       "       -0.02921716,  0.00987816, -0.09089072,  0.01728344, -0.04664449,\n",
       "       -0.06219688,  0.00240657,  0.00595597,  0.05719798, -0.05090652,\n",
       "       -0.02380582,  0.00902964, -0.08242439,  0.01991959, -0.01238719,\n",
       "        0.03369737, -0.01900204,  0.03301552,  0.00272696, -0.02060947,\n",
       "        0.04784526, -0.08923327,  0.08908195,  0.03406764,  0.02548733,\n",
       "        0.02444701, -0.03619544, -0.03153633, -0.02157967,  0.01211785,\n",
       "        0.02009911,  0.04491336, -0.00713507, -0.14395522,  0.15454863,\n",
       "        0.01383984,  0.00921869,  0.01396799, -0.01984234,  0.03981038,\n",
       "        0.04563572, -0.05211499,  0.02028685, -0.01807189,  0.07072775,\n",
       "       -0.08240999,  0.03538417, -0.04906363,  0.00601582,  0.00212226,\n",
       "        0.02595599, -0.07993259, -0.05341779,  0.02466225,  0.03422968,\n",
       "        0.1164176 ,  0.06914397, -0.03187271,  0.01225762, -0.01221895,\n",
       "        0.07817069, -0.02963013, -0.02462701, -0.03826473,  0.08744057,\n",
       "       -0.00425311,  0.03484006, -0.03791017, -0.05656181, -0.09749417,\n",
       "       -0.03384685,  0.060296  , -0.10316017,  0.04596346, -0.0421978 ,\n",
       "        0.08408698, -0.01670675,  0.01690596,  0.01921384,  0.00660057,\n",
       "        0.05186281, -0.03861122,  0.00961608,  0.05858411, -0.03272456,\n",
       "       -0.0473595 , -0.02170549, -0.08837824, -0.05309097,  0.01333806,\n",
       "        0.04046689,  0.03815232,  0.06601857,  0.01137957, -0.0584739 ,\n",
       "       -0.07111453,  0.01839523,  0.02796637, -0.03582467,  0.01126821,\n",
       "        0.06372557,  0.13032822, -0.0534598 , -0.0013019 ,  0.03374716,\n",
       "       -0.02044504,  0.03068233, -0.03362415, -0.01878908, -0.07303692,\n",
       "        0.02725952, -0.01330919,  0.01011602,  0.01231308, -0.00633971,\n",
       "        0.09232174,  0.02499162,  0.07458556,  0.00570423, -0.02133533,\n",
       "        0.00451516, -0.01959474, -0.03974517,  0.1421058 , -0.05869821,\n",
       "       -0.04250619,  0.00111427, -0.03009294,  0.05683763, -0.06968797,\n",
       "        0.03332453], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def context_repr(context):\n",
    "    left, _, right = context\n",
    "    words = tokenize(left) + tokenize(right)\n",
    "    return np.mean([w2v_model[w] for w in words if w in w2v_model],\n",
    "                    axis=0)\n",
    "\n",
    "context_repr(contexts[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос:** нужно ли использовать один и тот же лемматизатор для преобразования контекста и при построении word2vec модели?\n",
    "\n",
    "Дальше подготовим данные для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "word = 'горшок'\n",
    "senses, contexts = rl_wsd_labeled.get_contexts(\n",
    "    rl_wsd_labeled.contexts_filename('nouns', 'RuTenTen', word))\n",
    "xs = [ctx for ctx, _ in contexts]\n",
    "ys = np.array([int(s) - 1 for _, s in contexts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим векторные представления всех контекстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs_vec = np.array([context_repr(ctx) for ctx in xs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И обучим модель ``NearestCentroid`` используя кросс-валидацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81 ± 0.07\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(NearestCentroid(), X=xs_vec, y=ys, cv=5)\n",
    "print('Accuracy: {:.2f} ± {:.2f}'.format(np.mean(scores), 2 * np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша метрика тут - точность. Но сколько можно получить, предсказывая самое частотное значение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent sense baseline: 0.57\n"
     ]
    }
   ],
   "source": [
    "labels, counts = np.unique(ys, return_counts=True)\n",
    "print('Most frequent sense baseline: {:.2f}'.format(\n",
    "        np.mean(ys == labels[counts.argmax()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно обучить классификатор на всех примерах и задать ему свой контекст для дизамбигуации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = NearestCentroid()\n",
    "clf.fit(xs_vec, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Расширяющийся кверху сосуд с отверстием в дне (цветочный горшок)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(ctx):\n",
    "    pred, = clf.predict([context_repr(ctx)])\n",
    "    return senses[str(pred + 1)]\n",
    "\n",
    "predict(('он полил цветы в', 'горшках', 'и выключил свет'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ночной горшок'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(('он сел на', 'горшок', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задания - выбирать по вкусу:\n",
    "1. Можете ли вы заставить классификатор ошибиться?\n",
    "2. На каких тренировочных примерах он ошибается и почему?\n",
    "3. А какая точность для других слов?\n",
    "4. Как точность зависит от количества слов для обучения?\n",
    "5. ``NearestCentroid`` не умеет работать с косинусной мерой близости, но известно что она работает лучше чем евклидова - сделайте классификатор который использует её и сравните качество.\n",
    "6. Попробуйте использовать другие классификаторы из ``scikit-learn``, например ближайшие соседи, логистическую регрессию, другие. Какой классификатор работает лучше всех?\n",
    "7. В представлении контекста (``context_repr``) мы учитываем все слова. Но все ли слова одинаково важны? Можете ли вы изменить эту функцию так, чтобы она давала более качественное предстваление контекста?\n",
    "8. Какой будет результат если не использовать семантические вектора, а непосредственно слова?\n",
    "9. Насколько важно качество word2vec модели?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
